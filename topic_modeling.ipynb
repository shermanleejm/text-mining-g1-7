{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit744d58b894bb4db782f8537331854fe8",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import json\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import math\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 29047 entries, 0 to 29046\nData columns (total 9 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   Unnamed: 0    29047 non-null  int64 \n 1   title         29047 non-null  object\n 2   url           29047 non-null  object\n 3   crawled_time  29047 non-null  object\n 4   date          29047 non-null  object\n 5   domain        29047 non-null  object\n 6   author        19635 non-null  object\n 7   content       29047 non-null  object\n 8   topic_area    29047 non-null  object\ndtypes: int64(1), object(8)\nmemory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "df.info()\n",
    "\n",
    "## FOR TESTING ONLY\n",
    "# df = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Remove stop words and tokenise and stem\n",
    "def clean_content_SLOW(row):\n",
    "    content = re.sub(\"[^0-9a-zA-Z\\&]+\", \" \", row['content']).split(\" \")\n",
    "    processed = [stemmer.stem(lemmatizer.lemmatize(x.lower(), pos='v')) for x in content if x not in stopwords and x.strip() != \"\"]\n",
    "    return processed\n",
    "\n",
    "\n",
    "def clean_content_FAST(row):\n",
    "    content = re.sub(\"[^a-zA-Z\\&]+\", \" \", row['content']).split(\" \")\n",
    "    processed = [p_stemmer.stem(x.lower()) for x in content if x not in stopwords and x.strip() != \"\"]\n",
    "    return processed\n",
    "\n",
    "\n",
    "df[\"processed\"] = df.apply(lambda row: clean_content_SLOW(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dictionary(17086 unique tokens: ['&', '0&placement', '0&userid', '02', '1']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(df[\"processed\"])\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "print (dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in df[\"processed\"]]\n",
    "# bow_corpus[69]"
   ]
  },
  {
   "source": [
    "# TF-IDF TIME"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "## Print this if you want see \n",
    "# for doc in corpus_tfidf:\n",
    "#     print (doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Topic: 0 Word: 0.004*\"trump\" + 0.003*\"test\" + 0.003*\"case\" + 0.003*\"travel\" + 0.002*\"state\" + 0.002*\"countri\" + 0.002*\"flight\" + 0.002*\"presid\" + 0.002*\"china\" + 0.002*\"offici\"\nTopic: 1 Word: 0.004*\"oil\" + 0.004*\"0\" + 0.003*\"bank\" + 0.003*\"market\" + 0.003*\"price\" + 0.003*\"1\" + 0.003*\"stock\" + 0.002*\"million\" + 0.002*\"2019\" + 0.002*\"quarter\"\nTopic: 2 Word: 0.002*\"gm\" + 0.002*\"volkswagen\" + 0.002*\"china\" + 0.002*\"automak\" + 0.002*\"chines\" + 0.002*\"plant\" + 0.001*\"wuhan\" + 0.001*\"tesla\" + 0.001*\"car\" + 0.001*\"ford\"\nTopic: 3 Word: 0.003*\"china\" + 0.002*\"chines\" + 0.002*\"de\" + 0.002*\"case\" + 0.002*\"wuhan\" + 0.001*\"que\" + 0.001*\"flight\" + 0.001*\"infect\" + 0.001*\"passeng\" + 0.001*\"airlin\"\nTopic: 4 Word: 0.002*\"test\" + 0.002*\"patient\" + 0.002*\"symptom\" + 0.002*\"covid\" + 0.002*\"care\" + 0.002*\"i\" + 0.002*\"worker\" + 0.002*\"mask\" + 0.002*\"diseas\" + 0.002*\"infect\"\nTopic: 5 Word: 0.003*\"i\" + 0.003*\"leagu\" + 0.003*\"uk\" + 0.002*\"newspap\" + 0.002*\"game\" + 0.002*\"player\" + 0.002*\"school\" + 0.002*\"club\" + 0.002*\"back\" + 0.002*\"season\"\nTopic: 6 Word: 0.003*\"disney\" + 0.002*\"prison\" + 0.002*\"china\" + 0.002*\"iran\" + 0.001*\"fifa\" + 0.001*\"i\" + 0.001*\"compani\" + 0.001*\"case\" + 0.001*\"iranian\" + 0.001*\"film\"\nTopic: 7 Word: 0.003*\"soybean\" + 0.002*\"cineworld\" + 0.002*\"wheat\" + 0.002*\"china\" + 0.002*\"corn\" + 0.002*\"cent\" + 0.002*\"u\" + 0.002*\"s\" + 0.002*\"kane\" + 0.002*\"bushel\"\nTopic: 8 Word: 0.007*\"biden\" + 0.006*\"sander\" + 0.004*\"stock\" + 0.003*\"gold\" + 0.003*\"cramer\" + 0.003*\"democrat\" + 0.003*\"cnbc\" + 0.002*\"market\" + 0.002*\"trump\" + 0.002*\"s&p\"\nTopic: 9 Word: 0.004*\"forward\" + 0.004*\"compani\" + 0.004*\"statement\" + 0.003*\"custom\" + 0.003*\"2020\" + 0.003*\"oper\" + 0.002*\"look\" + 0.002*\"inform\" + 0.002*\"com\" + 0.002*\"product\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-2):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}